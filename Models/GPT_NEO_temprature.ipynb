{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1645020878765,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"n6edQBUZ3wg4","outputId":"076979d9-d913-4058-c445-f8e44b567900"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Feb 16 14:14:38 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pf5wd8q5kyGQ"},"outputs":[],"source":["%%capture\n","!pip install transformers\n","!pip install datasets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pB7l4Bu1tSJI"},"outputs":[],"source":["import warnings\n","import json\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IdmYxjWUX2JJ"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8670,"status":"ok","timestamp":1645020987295,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"FR6hJbqR4SW_","outputId":"e6dcfb29-5a5f-46d2-c519-df4aea01ae43"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["from typing import List\n","from pprint import pprint\n","import random\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","import math\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import get_linear_schedule_with_warmup, pipeline\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9745StCQwx-S"},"outputs":[],"source":["# Sizes: 125M, 1.3B, 2.7B\n","NEO_SIZE = \"125M\"\n","NEO_SAVE_NAME = NEO_SIZE.replace(\".\", \"-\") # Remove dot for filename saving\n","SEED = 57"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IqPZZUl3xRre"},"outputs":[],"source":["def set_seed(seed: int):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","set_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"CfVRUzk4Kh_k"},"source":["# Define Dataset object"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dVQLGioJvA7V"},"outputs":[],"source":["import spacy\n","from spacy.matcher import Matcher\n","from spacy.util import filter_spans\n","from spacy.symbols import ORTH\n","import spacy\n","from spacy.tokenizer import Tokenizer\n","SPACY_NLP = spacy.load(\"en_core_web_sm\")\n","# To tokenize just by space\n","SPACY_NLP.tokenizer = Tokenizer(SPACY_NLP.vocab)\n","\n","class docDataset:\n","    def __init__(self,  doc_name, text, vocab, clusters=None, gold_mentions=None):\n","        self.text = text\n","        self.sentences = text.split(\"[EOS]\")\n","        self.doc_name = doc_name\n","        self.gold_mentions = gold_mentions\n","        self.clusters = clusters\n","        self.window_size = 2\n","\n","        self.cluster_map = {}\n","        self.vocab = vocab\n","        self.mentions = {}\n","        self.context_sents = np.array([[-1,-1]])\n","        self.pairs = np.array([[-1,-1]])\n","        self.labels = np.array([])\n","\n","        self.create_cluster_map()\n","        # self.create_vocab()\n","        self.create_mention()\n","        \n","    \n","    def create_cluster_map(self):\n","        for id in self.clusters:\n","            tokens_in_cluster = self.clusters[id]\n","            for token in tokens_in_cluster:\n","                if token in self.cluster_map:\n","                    self.cluster_map[token].add(id) \n","                else:\n","                    self.cluster_map[token] = {id}\n","\n","    # def create_vocab(self):\n","    #     token_id = 1\n","    #     for i, sent in enumerate(self.sentences):\n","    #         annotated_tokens = SPACY_NLP(sent)\n","    #         self.vocab += [token.text for token in annotated_tokens]\n","    \n","    def create_mention(self):\n","        for i in range(len(self.sentences)):\n","            self.mentions[i] = []\n","\n","        if self.gold_mentions:\n","            for m_id in self.gold_mentions:\n","                mention_info = self.gold_mentions[m_id]\n","                mention_token_ids = mention_info[\"tokens_ids\"]\n","                mention_text = \" \".join(mention_info[\"tokens\"]) # \n","                sent_id = int(mention_info[\"sentence_id\"])  # TODO: need to change for new index, as the original xml starts from 0\n","               \n","                annotation = {\"mention\":mention_text,\n","                              \"start_token_id\": mention_token_ids[0],\n","                              \"end_token_id\": mention_token_ids[-1]}\n","                self.mentions[sent_id].append(annotation)\n","        else:\n","            raise Exception(\"TODO: need to add mentions if there is no gold data\")\n","\n","\n","    def decode_mention(self, mention):\n","        start_token_id = mention['start_token_id']\n","        end_token_id = mention['end_token_id']\n","        decoded_mention = list(range(start_token_id, end_token_id + 1))\n","        \n","        return decoded_mention\n","\n","\n","    def label_pairs(self, mention1, mention2):\n","        if not self.cluster_map:\n","            raise Exception(\"No Label Data\")\n","\n","        cluster1 = []\n","        cluster2 = []\n","\n","        for t_id in mention1:\n","            if t_id in self.cluster_map:\n","                cluster1.append(self.cluster_map[t_id])\n","\n","        for t_id in mention2:\n","            if t_id in self.cluster_map:\n","                cluster2.append(self.cluster_map[t_id])\n","        \n","        if len(set().union(*cluster1).intersection(set().union(*cluster2))) > 0:\n","            return 1\n","        return 0 \n","\n","    def create_mention_pairs(self):\n","        n = len(self.sentences)\n","        if n == 1:\n","            self.window_size = 1\n","            self.mention_pairs_helper(0) # TODO: may need to change          \n","        else:\n","            for i in range(n-self.window_size):\n","                self.mention_pairs_helper(i) # TODO: may need to change\n","        self.pairs = self.pairs[1:,:]\n","        self.context_sents = self.context_sents[1:,:]\n","\n","    def mention_pairs_helper(self, start_idx = 1):\n","        sent_idxs = range(start_idx, start_idx+self.window_size)\n","        sents_mentions = []\n","        \n","        for i in sent_idxs:\n","            sents_mentions += self.mentions[i] \n","\n","        for i in range(len(sents_mentions)-1):\n","            for j in range(i+1, len(sents_mentions)):\n","                mention1, mention2 = (sents_mentions[i], sents_mentions[j])\n","                self.pairs = np.append(self.pairs, [(mention1,mention2)],axis = 0)\n","                \n","                if self.cluster_map:\n","                    decoded_mention1 = self.decode_mention(mention1)\n","                    decoded_mention2 = self.decode_mention(mention2)\n","                    label = self.label_pairs(decoded_mention1, decoded_mention2)\n","                    self.labels = np.append(self.labels, label)\n","                \n","                self.context_sents = np.append(self.context_sents,\n","                                               [(start_idx, start_idx+self.window_size-1)],\n","                                               axis = 0)\n","    def get_experiment_samples(self):\n","        samples = []\n","        for i in tqdm(range(len(self.pairs))):\n","            text = self.extract_sents_text(self.context_sents[i])\n","            pair = self.pairs[i]\n","            label = self.labels[i]\n","            samples.append([self.context_sents[i], text, pair, label])\n","        return samples\n","    \n","    def extract_sents_text(self, sent_ids):\n","        sents = \"\"\n","        sent_ids = list(set(sent_ids))\n","        for i in sent_ids:\n","            sents += self.sentences[i] # TODO: May need to change \n","        return sents\n"]},{"cell_type":"markdown","metadata":{"id":"qEupatx6K_o9"},"source":["# Load Gold Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23080,"status":"ok","timestamp":1645021012993,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"ni9SdDqpHcme","outputId":"e30e4de3-ec8e-4629-8c67-b22dacd6c209"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["import random\n","from google.colab import drive\n","import pickle\n","drive.mount('/content/drive',force_remount=True)\n","\n","# Make sure to click \"Add shortcut to drive\" for the \"Coref-for-GPT\" folder\n","gdrive_dir_path = \"/content/drive/MyDrive/Coref-for-GPT\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FFrc9YSKGUEJ"},"outputs":[],"source":["local_path = \"\"\n","\n","# Change this to \"local_path\" if you run the notebook locally\n","root_path = gdrive_dir_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_bZUktrx43uU"},"outputs":[],"source":["# Path to the ecb data\n","ecb_path = f\"{root_path}/Data/ECB+/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3362,"status":"ok","timestamp":1645021016353,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"0sRB8oRa4uRN","outputId":"36193f75-9611-448c-b4c9-164e130236b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["gold  original\tprocessed\n"]}],"source":["!ls drive/MyDrive/Coref-for-GPT/Data/ECB+"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1024,"status":"ok","timestamp":1645021024805,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"anF6lbmlayCU","outputId":"f23c999f-36ca-471a-f2eb-26b60f662648"},"outputs":[{"name":"stdout","output_type":"stream","text":["558\n"]}],"source":["file_path = ecb_path + \"processed/train_with_new_index.json\"\n","with open(file_path) as f:\n","    train = json.load(f)\n","print(len(train))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":846,"status":"ok","timestamp":1645021026776,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"ahcxfIlOMIUA","outputId":"a2d30320-698d-4d86-cb83-36598aec5dff"},"outputs":[{"name":"stdout","output_type":"stream","text":["192\n"]}],"source":["file_path = ecb_path + \"processed/dev_with_new_index.json\"\n","with open(file_path) as f:\n","    dev = json.load(f)\n","print(len(dev))"]},{"cell_type":"markdown","metadata":{"id":"sj-giiriolC4"},"source":["# Generate Prompt\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wtbc_qFVgvlK"},"outputs":[],"source":["def generate_prompt(template, text, mention_pair, text_token = \"[TEXT]\", mention1_token = \"[MENTION1]\", mention2_token = \"[MENTION2]\"):\n","    template = template.replace(text_token, text)\n","    template = template.replace(mention1_token, mention_pair[0])\n","    template = template.replace(mention2_token, mention_pair[1])\n","    return template\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfvK6TtlTQ5r"},"outputs":[],"source":["def create_prefix(examples, template, answer_choices):\n","    prefix = \"\"\n","    for (text, mention_pair, label) in examples:\n","        label_text = answer_choices[int(label)]\n","        prefix += generate_prompt(template, text, mention_pair) + \" \" +label_text+ \"\\n\"\n","    return prefix"]},{"cell_type":"markdown","metadata":{"id":"e0jjTUmxVe9t"},"source":["## Define Parameters for Prefix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7k0CtvcNUCds"},"outputs":[],"source":["# Define number of examples to generate for prefix\n","n_examples = 10\n","answer_choices = [\"No\", \"Yes\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7V1dn6ahUvX4"},"outputs":[],"source":["# We will experiment with these prompt separately\n","templates = [\"'[TEXT]' In previous sentences, does '[MENTION2]' refer to '[MENTION1]'? Yes or no?\",\n","             \"'[TEXT]' Here, by '[MENTION2]' they mean '[MENTION1]'? Yes or no?\",\n","             \"'[TEXT]' Here, does '[MENTION2]' stand for '[MENTION1]'? Yes or no? \",\n","             \"'[TEXT]' In the passage above, can '[MENTION2]' be replaced by '[MENTION1]'? Yes or no?\",\n","             \"'[TEXT]' I think '[MENTION2]' means '[MENTION1]'. Yes or no?\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"--vS9LN-l2oo"},"outputs":[],"source":["simple_examples = [[\"Anna told her friends that she was about to go to college.\", [\"Anna\",\"she\"], 1],\n","                   [\"Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party\", [\"Eva\",\"her\"], 0],\n","                   [\"Paul Allen was born on Jan 21, 1953. Allen attended Lakeside School, where he befriended Bill Gates\", [\"Paul Allen\",\"Allen\"], 1],\n","                   [\"A dog named Teddy ran to his owner Jane. Jane loves her dog.\", [\"Teddy\",\"Jane\"], 0],\n","                   [\"I bought 3 bottles of wine today, when I went to John Doe’s store\", [\"I\", \"John Doe\"], 0],\n","                   [\"Vasco told me yesterday that is his final exam went pretty well. Vasco worked really hard.\", [\"Vasco\", \"Vasco\"], 1],\n","                   [\"Her car was so fast, that it went past the speed limit\", [\"Her car\", \"it\"], 1],\n","                   [\"Some of our colleagues are going to be supportive. These kinds of people will earn our gratitude\", [\"Some of our colleagues\", \"our gratitude\"], 0],\n","                   [\"Barack Obama won the midterm elections, so he was in office for 2 terms\", [\"Barack Obama\", \"he\"], 1],\n","                   [\"Our neighbors dislike the music. If they are angry, the cops will show up soon\", [\"they\", \"the cops\"], 0]\n","                   ]"]},{"cell_type":"markdown","metadata":{"id":"3rvouH4dVnGK"},"source":["## Generate Prefix"]},{"cell_type":"markdown","metadata":{"id":"-LtD8YlsTBta"},"source":["### 1. Mannually create prefix "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1645021035929,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"CzB9lcXsJb93","outputId":"324316ab-0048-459a-eef6-db31bf94a76a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prefix based on template 1:  'Anna told her friends that she was about to go to college.' In previous sentences, does 'she' refer to 'Anna'? Yes or no? Yes\n","'Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party' In previous sentences, does 'her' refer to 'Eva'? Yes or no? No\n","'Paul Allen was born on Jan 21, 1953. Allen attended Lakeside School, where he befriended Bill Gates' In previous sentences, does 'Allen' refer to 'Paul Allen'? Yes or no? Yes\n","'A dog named Teddy ran to his owner Jane. Jane loves her dog.' In previous sentences, does 'Jane' refer to 'Teddy'? Yes or no? No\n","'I bought 3 bottles of wine today, when I went to John Doe’s store' In previous sentences, does 'John Doe' refer to 'I'? Yes or no? No\n","'Vasco told me yesterday that is his final exam went pretty well. Vasco worked really hard.' In previous sentences, does 'Vasco' refer to 'Vasco'? Yes or no? Yes\n","'Her car was so fast, that it went past the speed limit' In previous sentences, does 'it' refer to 'Her car'? Yes or no? Yes\n","'Some of our colleagues are going to be supportive. These kinds of people will earn our gratitude' In previous sentences, does 'our gratitude' refer to 'Some of our colleagues'? Yes or no? No\n","'Barack Obama won the midterm elections, so he was in office for 2 terms' In previous sentences, does 'he' refer to 'Barack Obama'? Yes or no? Yes\n","'Our neighbors dislike the music. If they are angry, the cops will show up soon' In previous sentences, does 'the cops' refer to 'they'? Yes or no? No\n","\n"]}],"source":["prefixes_simple = []\n","\n","for template in templates:\n","    prefix = create_prefix(simple_examples[:n_examples], template, answer_choices)\n","    prefixes_simple.append(prefix)\n","print(\"Prefix based on template 1: \", prefixes_simple[0])"]},{"cell_type":"markdown","metadata":{"id":"PApfbpWWS0Zx"},"source":["### 2. Create prefix from SuperGLUE "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200,"referenced_widgets":["7076edac42574cfa91886c1526164ff8","477aa4822a364c398b17b9eb7c0a1b21","664eb6dd34ba4c0dac272a8ac79b6b03","5b54b9c501cc4770abb8fa3faa7f94e6","b382db97d90c4ed9bb6116e2d70176bb","b7d5586a137b4a318fc0e7160ae13613","caebeae14d25422f9f2a83e88981ebe0","a9b9e81a3570409ba48d907f878950cb","29b42f6186bb481bb854ad0f0b185255","257785ac42914a62904b89a986fe5bcf","ece9a2ccf8594878becb4fa531fb400c","8e48d2775c584922a4bd76ef4da6960c","49afecb48bc24563aecbcb4b4759ddf5","dd9062a77020431a988990c57215fde1","ef1c7f90c9164f4592ecb004478b32c6","f5d1b023c9ff404c931d8f21aef67d2a","8edb074b313b48c0ab6e7b33229b7b14","f4def5ba293943d695f1c53a3e966398","846e00d05c444a029119698673fedac6","5ecb25da55ac4caa8738e0f237106e6a","f7fc3bd22ca942cca00bae7b38310a9b","e868898a8b624945bdf328c1a691d492","72824090c5be4b0fac5ace11f63198f0","7312066626474b99a0843cb45b622466","a483e018792141939a64e1d752fe54dc","642e62327f09481cbb3eaee393bf4c47","7de9a39719264c2e9114ad48fd347c66","68175a3852084de79743ef91f94362b8","bfb299f58a80424fba139f6ba9a3ba7a","a4e121094a7b431ab4993fe35f39397a","b12931c87df44deda723107286375f05","72ab2c1d08de4c62b6aeccba61c7fb5f","ba22aebfdb544aad83130732effa26d5","0a586a5b02d94f98bdd43b8968a008c8","93360276fb57431bbbce2f632d52f0d3","c85e7735da3740b39c3ec5aa97a170b7","59ce08cf1a0744a59a909c8ca0f1479d","40b86517f54c4984a97f2c279a4a6aa6","d92b39134ad640e2b1f6461cb15dfc6e","c3acd2232c4e433f88af4bc8b634da6d","01115ca094aa4e219c152c479fa1f13b","e625473a56d7423e901e6e8d8d11a5b4","d3c22cbc812947f38bcf9be8fe1d4763","4341a76c5c744ff99832df365a9bd096","260edfed9cec411db524193e3b96aa7a","a29a397fd63d475a8fa26e97d0c78150","14372532977a447a9cbe99676419a1bf","5774486f05b0469eac980223644936ab","1c90873b151e46d695de01da82940ed9","0884e03afa97438e9332d1c9c7dd3d8f","463563e2389a4e4cab6344b7a0bf73e0","a14d932614db4cc9a320f6a2c1e89fb9","cb1b818f3c254961a2a166c0c2d8b5c3","4703848be1a44c8e9fef6a8337874b48","b6ec91c0c92b4c0faaed75d0fb393e92","d792e8b5289b402f87869a2f655517e6","4ff3923570b04a23946564e7a04a4eeb","c68d74423795482cae935c614b3d8aad","94b06c7011a245dcb8d75bba0d1817bc","4d626c20ef854689be9260686a96f967","770946fdcb274169ae09d34dac3797fa","3857c662ab5448b3a895e35174717109","0fad219c4d6e46f5a504664ce4246e4b","fe58ea91b19f45689534fc88433dfcf3","e2f03c5e3c8a428981b5f006e417cc53","fde35d35de9a4b2cb539135e7a549c91","9ac3331b9fc14071b9829b1387f8be26","dd2142f7ddf746ecb12ea566f285af7c","70a7853a03cb4a059f6e327ea8ea7095","474e63ea64c44f6bbda84667d6a74036","c086d97960684d56b0d30ec88fc49419","a605195ba0d542c7b0a6cbc690975a8e","22d02623765940b48a06fd7f5fe51cff","a79d086b10d94cfeb3d0780cca12ae09","69c098842fd444e3b16ddcc0d00a7593","911dd7b8186d49a09e568c60d33ddabe","23c7444d8bd2482e9324fe06fd93904d"]},"executionInfo":{"elapsed":3711,"status":"ok","timestamp":1645021042152,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"C89TZGkWTbiz","outputId":"6ae4b119-ffc2-4c57-a472-5f595bb237cf"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7076edac42574cfa91886c1526164ff8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/9.47k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e48d2775c584922a4bd76ef4da6960c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/8.23k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset super_glue/wsc.fixed (download: 31.98 KiB, generated: 139.73 KiB, post-processed: Unknown size, total: 171.72 KiB) to /root/.cache/huggingface/datasets/super_glue/wsc.fixed/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72824090c5be4b0fac5ace11f63198f0","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/32.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a586a5b02d94f98bdd43b8968a008c8","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"260edfed9cec411db524193e3b96aa7a","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d792e8b5289b402f87869a2f655517e6","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset super_glue downloaded and prepared to /root/.cache/huggingface/datasets/super_glue/wsc.fixed/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ac3331b9fc14071b9829b1387f8be26","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","super_glue = load_dataset(\"super_glue\", 'wsc.fixed')\n","super_glue_train = super_glue[\"train\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GsRRTgAXToJK"},"outputs":[],"source":["def parse_superglue(data):\n","    texts = data[\"text\"]\n","    pairs = list(zip(data[\"span1_text\"], data[\"span2_text\"]))\n","    labels = data[\"label\"]\n","    return texts, pairs, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sl7atfKH24n9"},"outputs":[],"source":["def get_examples_superglue(n, texts, pairs, labels,):\n","    '''Return examples for prefix. \n","            Parameters:\n","                    n (int): total number of examples, expected to be an even number\n","                    texts (list): list of text \n","                    pairs (list): list of mention pairs\n","                    labels (list): list of labels\n","\n","            Returns:\n","                    examples (list): list of examples\n","    '''\n","    # we want a balanced example set\n","    n_positives = n_negatives = n//2\n","    i = 0\n","    examples = []\n","    while (n_positives > 0) or (n_negatives > 0):\n","        text = texts[i]\n","        mention_pair = pairs[i]\n","        label = labels[i]\n","        if (label == 1) and (n_positives > 0):\n","            examples.append([text, mention_pair, label])\n","            n_positives -= 1\n","\n","        if (label == 0) and (n_negatives > 0):\n","            examples.append([text, mention_pair, label])\n","            n_negatives -= 1  \n","        i += 1\n","    return examples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1645021042152,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"rIq0ONmeTroP","outputId":"1591c81a-7431-4904-a021-7ed4e46bb1b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prefix based on template 1:  'Mark told Pete many lies about himself, which Pete included in his book. He should have been more skeptical.' In previous sentences, does 'He' refer to 'Mark'? Yes or no? No\n","'The mothers of Arthur and Celeste have come to the town to fetch them. They are very happy to have them back, but they scold them just the same because they ran away.' In previous sentences, does 'them' refer to 'mothers'? Yes or no? No\n","'Mark was close to Mr. Singer 's heels. He heard him calling for the captain, promising him, in the jargon everyone talked that night, that not one thing should be damaged on the ship except only the ammunition, but the captain and all his crew had best stay in the cabin until the work was over' In previous sentences, does 'He' refer to 'Mr. Singer'? Yes or no? No\n","'The pony behaved well, sir, and showed no vice; but at last he just threw up his heels and tipped the young gentleman into the thorn hedge. He wanted me to help him out, but I hope you will excuse me, sir, I did not feel inclined to do so.' In previous sentences, does 'He' refer to 'young gentleman'? Yes or no? Yes\n","'I poured water from the bottle into the cup until it was full.' In previous sentences, does 'it' refer to 'the cup'? Yes or no? Yes\n","'Dan had to stop Bill from toying with the injured bird. He is very compassionate.' In previous sentences, does 'He' refer to 'Dan'? Yes or no? Yes\n","'Sam Goodman 's biography of the Spartan general Xenophanes conveys a vivid sense of the difficulties he faced in his childhood.' In previous sentences, does 'he' refer to 'Goodman'? Yes or no? No\n","'Pam's parents came home and found her having sex with her boyfriend, Paul. They were furious about it.' In previous sentences, does 'They' refer to 'Pam's parents'? Yes or no? Yes\n","'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very hurt.' In previous sentences, does 'He' refer to 'Bob'? Yes or no? Yes\n","'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very ungrateful.' In previous sentences, does 'He' refer to 'Bob'? Yes or no? No\n","\n"]}],"source":["super_glue_texts, super_glue_pairs, super_glue_labels = parse_superglue(super_glue_train)\n","\n","superglue_examples = get_examples_superglue(n_examples, super_glue_texts, \n","                                            super_glue_pairs, super_glue_labels)\n","prefixes_super_glue = []\n","\n","for template in templates:\n","    prefix = create_prefix(superglue_examples, template, answer_choices)\n","    prefixes_super_glue.append(prefix)\n","print(\"Prefix based on template 1: \", prefixes_super_glue[0])"]},{"cell_type":"markdown","metadata":{"id":"aPbkWs8-RCma"},"source":["### 3. Create prefix from ECB+ train "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKno9hMJ-szL"},"outputs":[],"source":["def extract_sents_text(doc, sent_ids):\n","    sents = \"\"\n","    for i in sent_ids:\n","        sents += doc.sentences[i] #+ \" \"\n","    return sents\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k3Obon5TATys"},"outputs":[],"source":["def get_example_info(doc, filter, idx):\n","    text_ids = doc.context_sents[filter]\n","    text = extract_sents_text(doc, text_ids[idx])\n","    m1, m2 = doc.pairs[filter][idx]\n","    mention_pair = [m1[\"mention\"], m2[\"mention\"]]\n","    label = doc.labels[filter][idx]\n","    return text, mention_pair, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p86gSZR0SznD"},"outputs":[],"source":["def get_examples_ecb(n, train, train_docs):\n","    examples = []\n","    pos_n = neg_n = n//2\n","    for i in range(len(train_docs)):\n","        if pos_n <= 0:\n","            return examples\n","        doc_name = train_docs[i]\n","        text, toks, mentions, clusters = train[doc_name]\n","        sample = docDataset(doc_name, text, toks, clusters, mentions)\n","        sample.create_mention_pairs()\n","        \n","        pos_filter = (sample.labels == 1)\n","        neg_filter = (sample.labels == 0)\n","        \n","        if np.sum(pos_filter) == 0:\n","            print(\"%s has no positive examples\"%(doc_name))\n","            continue\n","        else:\n","            pos_text, pos_mention_pair, pos_label = get_example_info(sample, pos_filter, 0)\n","            examples.append([pos_text, pos_mention_pair, pos_label])\n","\n","            neg_text, neg_mention_pair, neg_label = get_example_info(sample, neg_filter, 0)\n","            examples.append([neg_text, neg_mention_pair, neg_label])\n","            pos_n -= 1\n","            "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1645021044055,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"bm0thvtvBWob","outputId":"d83029d8-4097-42e1-b936-583fb746fdbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["20_10ecbplus.xml has no positive examples\n","20_11ecbplus.xml has no positive examples\n","20_1ecb.xml has no positive examples\n","20_4ecb.xml has no positive examples\n","Prefix based on template 1:  ' An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday.  The tremor struck an area around the town of Dargahan on Qeshm island, at the entrance to the Persian Gulf, injuring five people and damaging buildings. ' In previous sentences, does 'an area around the town of Dargahan on Qeshm island , at the entrance to the Persian Gulf' refer to 'Qeshm island off Iran 's southern coast'? Yes or no? Yes\n","'Five Wounded by Quake in Southern Iran  An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday. ' In previous sentences, does 'Richter scale' refer to '5.6'? Yes or no? No\n","' Ten dead in southern Iran quake  A powerful earthquake has hit southern Iran, killing at least 10 people, injuring dozens more and damaging several villages, officials say. ' In previous sentences, does 'people' refer to 'Ten'? Yes or no? Yes\n","' Last Updated: Monday, 28 November 2005, 02: 24 GMT  Ten dead in southern Iran quake ' In previous sentences, does 'Ten' refer to 'Monday , 28 November 2005 , 02 : 24 GMT'? Yes or no? No\n","' Aftershocks jolt Iran's Qeshm island, death toll rises to 10  The sixth aftershock shook this southern Iranian island in the Persian Gulf on Monday as death toll from a strong earthquake a day before rose to 10. ' In previous sentences, does 'southern Iranian island in the Persian Gulf' refer to 'Iran 's Qeshm island'? Yes or no? Yes\n","' 11/28/05  Aftershocks jolt Iran's Qeshm island, death toll rises to 10 ' In previous sentences, does 'Iran 's Qeshm island' refer to '11/28/05'? Yes or no? No\n","'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' In previous sentences, does 'on the outskirts of Dargahan , a small town on the island' refer to 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province'? Yes or no? Yes\n","'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' In previous sentences, does 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province' refer to '5.6-magnitude'? Yes or no? No\n","' Nov 28, 2005  Iranian rescue workers handed out blankets, food and water Monday to survivors of a powerful earthquake on a Gulf island that killed 10 people and forced villagers to spend the night in tents. ' In previous sentences, does 'villagers' refer to 'survivors'? Yes or no? Yes\n","'http://www.terradaily.com/news/disaster-management-05zzzzzc. html  Iran Villagers Shelter In Tents After Killer Quake ' In previous sentences, does 'In Tents' refer to 'Villagers'? Yes or no? No\n","\n"]}],"source":["ecb_examples = get_examples_ecb(n_examples, train, list(train.keys()))\n","prefixes_ecb = []\n","\n","for template in templates:\n","    prefix = create_prefix(ecb_examples, template, answer_choices)\n","    prefixes_ecb.append(prefix)\n","print(\"Prefix based on template 1: \", prefixes_ecb[0])"]},{"cell_type":"markdown","metadata":{"id":"7quPsPg7TTo4"},"source":["# Create Generator"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1645021046265,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"l5YQwcJQNyTu","outputId":"3ba208ef-43fa-4830-dde1-2215725b8fae"},"outputs":[{"data":{"text/plain":["{'ecb': [\"' An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday.  The tremor struck an area around the town of Dargahan on Qeshm island, at the entrance to the Persian Gulf, injuring five people and damaging buildings. ' In previous sentences, does 'an area around the town of Dargahan on Qeshm island , at the entrance to the Persian Gulf' refer to 'Qeshm island off Iran 's southern coast'? Yes or no? Yes\\n'Five Wounded by Quake in Southern Iran  An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday. ' In previous sentences, does 'Richter scale' refer to '5.6'? Yes or no? No\\n' Ten dead in southern Iran quake  A powerful earthquake has hit southern Iran, killing at least 10 people, injuring dozens more and damaging several villages, officials say. ' In previous sentences, does 'people' refer to 'Ten'? Yes or no? Yes\\n' Last Updated: Monday, 28 November 2005, 02: 24 GMT  Ten dead in southern Iran quake ' In previous sentences, does 'Ten' refer to 'Monday , 28 November 2005 , 02 : 24 GMT'? Yes or no? No\\n' Aftershocks jolt Iran's Qeshm island, death toll rises to 10  The sixth aftershock shook this southern Iranian island in the Persian Gulf on Monday as death toll from a strong earthquake a day before rose to 10. ' In previous sentences, does 'southern Iranian island in the Persian Gulf' refer to 'Iran 's Qeshm island'? Yes or no? Yes\\n' 11/28/05  Aftershocks jolt Iran's Qeshm island, death toll rises to 10 ' In previous sentences, does 'Iran 's Qeshm island' refer to '11/28/05'? Yes or no? No\\n'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' In previous sentences, does 'on the outskirts of Dargahan , a small town on the island' refer to 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province'? Yes or no? Yes\\n'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' In previous sentences, does 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province' refer to '5.6-magnitude'? Yes or no? No\\n' Nov 28, 2005  Iranian rescue workers handed out blankets, food and water Monday to survivors of a powerful earthquake on a Gulf island that killed 10 people and forced villagers to spend the night in tents. ' In previous sentences, does 'villagers' refer to 'survivors'? Yes or no? Yes\\n'http://www.terradaily.com/news/disaster-management-05zzzzzc. html  Iran Villagers Shelter In Tents After Killer Quake ' In previous sentences, does 'In Tents' refer to 'Villagers'? Yes or no? No\\n\",\n","  \"' An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday.  The tremor struck an area around the town of Dargahan on Qeshm island, at the entrance to the Persian Gulf, injuring five people and damaging buildings. ' Here, by 'an area around the town of Dargahan on Qeshm island , at the entrance to the Persian Gulf' they mean 'Qeshm island off Iran 's southern coast'? Yes or no? Yes\\n'Five Wounded by Quake in Southern Iran  An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday. ' Here, by 'Richter scale' they mean '5.6'? Yes or no? No\\n' Ten dead in southern Iran quake  A powerful earthquake has hit southern Iran, killing at least 10 people, injuring dozens more and damaging several villages, officials say. ' Here, by 'people' they mean 'Ten'? Yes or no? Yes\\n' Last Updated: Monday, 28 November 2005, 02: 24 GMT  Ten dead in southern Iran quake ' Here, by 'Ten' they mean 'Monday , 28 November 2005 , 02 : 24 GMT'? Yes or no? No\\n' Aftershocks jolt Iran's Qeshm island, death toll rises to 10  The sixth aftershock shook this southern Iranian island in the Persian Gulf on Monday as death toll from a strong earthquake a day before rose to 10. ' Here, by 'southern Iranian island in the Persian Gulf' they mean 'Iran 's Qeshm island'? Yes or no? Yes\\n' 11/28/05  Aftershocks jolt Iran's Qeshm island, death toll rises to 10 ' Here, by 'Iran 's Qeshm island' they mean '11/28/05'? Yes or no? No\\n'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' Here, by 'on the outskirts of Dargahan , a small town on the island' they mean 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province'? Yes or no? Yes\\n'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' Here, by 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province' they mean '5.6-magnitude'? Yes or no? No\\n' Nov 28, 2005  Iranian rescue workers handed out blankets, food and water Monday to survivors of a powerful earthquake on a Gulf island that killed 10 people and forced villagers to spend the night in tents. ' Here, by 'villagers' they mean 'survivors'? Yes or no? Yes\\n'http://www.terradaily.com/news/disaster-management-05zzzzzc. html  Iran Villagers Shelter In Tents After Killer Quake ' Here, by 'In Tents' they mean 'Villagers'? Yes or no? No\\n\",\n","  \"' An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday.  The tremor struck an area around the town of Dargahan on Qeshm island, at the entrance to the Persian Gulf, injuring five people and damaging buildings. ' Here, does 'an area around the town of Dargahan on Qeshm island , at the entrance to the Persian Gulf' stand for 'Qeshm island off Iran 's southern coast'? Yes or no?  Yes\\n'Five Wounded by Quake in Southern Iran  An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday. ' Here, does 'Richter scale' stand for '5.6'? Yes or no?  No\\n' Ten dead in southern Iran quake  A powerful earthquake has hit southern Iran, killing at least 10 people, injuring dozens more and damaging several villages, officials say. ' Here, does 'people' stand for 'Ten'? Yes or no?  Yes\\n' Last Updated: Monday, 28 November 2005, 02: 24 GMT  Ten dead in southern Iran quake ' Here, does 'Ten' stand for 'Monday , 28 November 2005 , 02 : 24 GMT'? Yes or no?  No\\n' Aftershocks jolt Iran's Qeshm island, death toll rises to 10  The sixth aftershock shook this southern Iranian island in the Persian Gulf on Monday as death toll from a strong earthquake a day before rose to 10. ' Here, does 'southern Iranian island in the Persian Gulf' stand for 'Iran 's Qeshm island'? Yes or no?  Yes\\n' 11/28/05  Aftershocks jolt Iran's Qeshm island, death toll rises to 10 ' Here, does 'Iran 's Qeshm island' stand for '11/28/05'? Yes or no?  No\\n'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' Here, does 'on the outskirts of Dargahan , a small town on the island' stand for 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province'? Yes or no?  Yes\\n'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' Here, does 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province' stand for '5.6-magnitude'? Yes or no?  No\\n' Nov 28, 2005  Iranian rescue workers handed out blankets, food and water Monday to survivors of a powerful earthquake on a Gulf island that killed 10 people and forced villagers to spend the night in tents. ' Here, does 'villagers' stand for 'survivors'? Yes or no?  Yes\\n'http://www.terradaily.com/news/disaster-management-05zzzzzc. html  Iran Villagers Shelter In Tents After Killer Quake ' Here, does 'In Tents' stand for 'Villagers'? Yes or no?  No\\n\",\n","  \"' An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday.  The tremor struck an area around the town of Dargahan on Qeshm island, at the entrance to the Persian Gulf, injuring five people and damaging buildings. ' In the passage above, can 'an area around the town of Dargahan on Qeshm island , at the entrance to the Persian Gulf' be replaced by 'Qeshm island off Iran 's southern coast'? Yes or no? Yes\\n'Five Wounded by Quake in Southern Iran  An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday. ' In the passage above, can 'Richter scale' be replaced by '5.6'? Yes or no? No\\n' Ten dead in southern Iran quake  A powerful earthquake has hit southern Iran, killing at least 10 people, injuring dozens more and damaging several villages, officials say. ' In the passage above, can 'people' be replaced by 'Ten'? Yes or no? Yes\\n' Last Updated: Monday, 28 November 2005, 02: 24 GMT  Ten dead in southern Iran quake ' In the passage above, can 'Ten' be replaced by 'Monday , 28 November 2005 , 02 : 24 GMT'? Yes or no? No\\n' Aftershocks jolt Iran's Qeshm island, death toll rises to 10  The sixth aftershock shook this southern Iranian island in the Persian Gulf on Monday as death toll from a strong earthquake a day before rose to 10. ' In the passage above, can 'southern Iranian island in the Persian Gulf' be replaced by 'Iran 's Qeshm island'? Yes or no? Yes\\n' 11/28/05  Aftershocks jolt Iran's Qeshm island, death toll rises to 10 ' In the passage above, can 'Iran 's Qeshm island' be replaced by '11/28/05'? Yes or no? No\\n'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' In the passage above, can 'on the outskirts of Dargahan , a small town on the island' be replaced by 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province'? Yes or no? Yes\\n'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' In the passage above, can 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province' be replaced by '5.6-magnitude'? Yes or no? No\\n' Nov 28, 2005  Iranian rescue workers handed out blankets, food and water Monday to survivors of a powerful earthquake on a Gulf island that killed 10 people and forced villagers to spend the night in tents. ' In the passage above, can 'villagers' be replaced by 'survivors'? Yes or no? Yes\\n'http://www.terradaily.com/news/disaster-management-05zzzzzc. html  Iran Villagers Shelter In Tents After Killer Quake ' In the passage above, can 'In Tents' be replaced by 'Villagers'? Yes or no? No\\n\",\n","  \"' An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday.  The tremor struck an area around the town of Dargahan on Qeshm island, at the entrance to the Persian Gulf, injuring five people and damaging buildings. ' I think 'an area around the town of Dargahan on Qeshm island , at the entrance to the Persian Gulf' means 'Qeshm island off Iran 's southern coast'. Yes or no? Yes\\n'Five Wounded by Quake in Southern Iran  An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday. ' I think 'Richter scale' means '5.6'. Yes or no? No\\n' Ten dead in southern Iran quake  A powerful earthquake has hit southern Iran, killing at least 10 people, injuring dozens more and damaging several villages, officials say. ' I think 'people' means 'Ten'. Yes or no? Yes\\n' Last Updated: Monday, 28 November 2005, 02: 24 GMT  Ten dead in southern Iran quake ' I think 'Ten' means 'Monday , 28 November 2005 , 02 : 24 GMT'. Yes or no? No\\n' Aftershocks jolt Iran's Qeshm island, death toll rises to 10  The sixth aftershock shook this southern Iranian island in the Persian Gulf on Monday as death toll from a strong earthquake a day before rose to 10. ' I think 'southern Iranian island in the Persian Gulf' means 'Iran 's Qeshm island'. Yes or no? Yes\\n' 11/28/05  Aftershocks jolt Iran's Qeshm island, death toll rises to 10 ' I think 'Iran 's Qeshm island' means '11/28/05'. Yes or no? No\\n'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' I think 'on the outskirts of Dargahan , a small town on the island' means 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province'. Yes or no? Yes\\n'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' I think 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province' means '5.6-magnitude'. Yes or no? No\\n' Nov 28, 2005  Iranian rescue workers handed out blankets, food and water Monday to survivors of a powerful earthquake on a Gulf island that killed 10 people and forced villagers to spend the night in tents. ' I think 'villagers' means 'survivors'. Yes or no? Yes\\n'http://www.terradaily.com/news/disaster-management-05zzzzzc. html  Iran Villagers Shelter In Tents After Killer Quake ' I think 'In Tents' means 'Villagers'. Yes or no? No\\n\"],\n"," 'simple': [\"'Anna told her friends that she was about to go to college.' In previous sentences, does 'she' refer to 'Anna'? Yes or no? Yes\\n'Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party' In previous sentences, does 'her' refer to 'Eva'? Yes or no? No\\n'Paul Allen was born on Jan 21, 1953. Allen attended Lakeside School, where he befriended Bill Gates' In previous sentences, does 'Allen' refer to 'Paul Allen'? Yes or no? Yes\\n'A dog named Teddy ran to his owner Jane. Jane loves her dog.' In previous sentences, does 'Jane' refer to 'Teddy'? Yes or no? No\\n'I bought 3 bottles of wine today, when I went to John Doe’s store' In previous sentences, does 'John Doe' refer to 'I'? Yes or no? No\\n'Vasco told me yesterday that is his final exam went pretty well. Vasco worked really hard.' In previous sentences, does 'Vasco' refer to 'Vasco'? Yes or no? Yes\\n'Her car was so fast, that it went past the speed limit' In previous sentences, does 'it' refer to 'Her car'? Yes or no? Yes\\n'Some of our colleagues are going to be supportive. These kinds of people will earn our gratitude' In previous sentences, does 'our gratitude' refer to 'Some of our colleagues'? Yes or no? No\\n'Barack Obama won the midterm elections, so he was in office for 2 terms' In previous sentences, does 'he' refer to 'Barack Obama'? Yes or no? Yes\\n'Our neighbors dislike the music. If they are angry, the cops will show up soon' In previous sentences, does 'the cops' refer to 'they'? Yes or no? No\\n\",\n","  \"'Anna told her friends that she was about to go to college.' Here, by 'she' they mean 'Anna'? Yes or no? Yes\\n'Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party' Here, by 'her' they mean 'Eva'? Yes or no? No\\n'Paul Allen was born on Jan 21, 1953. Allen attended Lakeside School, where he befriended Bill Gates' Here, by 'Allen' they mean 'Paul Allen'? Yes or no? Yes\\n'A dog named Teddy ran to his owner Jane. Jane loves her dog.' Here, by 'Jane' they mean 'Teddy'? Yes or no? No\\n'I bought 3 bottles of wine today, when I went to John Doe’s store' Here, by 'John Doe' they mean 'I'? Yes or no? No\\n'Vasco told me yesterday that is his final exam went pretty well. Vasco worked really hard.' Here, by 'Vasco' they mean 'Vasco'? Yes or no? Yes\\n'Her car was so fast, that it went past the speed limit' Here, by 'it' they mean 'Her car'? Yes or no? Yes\\n'Some of our colleagues are going to be supportive. These kinds of people will earn our gratitude' Here, by 'our gratitude' they mean 'Some of our colleagues'? Yes or no? No\\n'Barack Obama won the midterm elections, so he was in office for 2 terms' Here, by 'he' they mean 'Barack Obama'? Yes or no? Yes\\n'Our neighbors dislike the music. If they are angry, the cops will show up soon' Here, by 'the cops' they mean 'they'? Yes or no? No\\n\",\n","  \"'Anna told her friends that she was about to go to college.' Here, does 'she' stand for 'Anna'? Yes or no?  Yes\\n'Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party' Here, does 'her' stand for 'Eva'? Yes or no?  No\\n'Paul Allen was born on Jan 21, 1953. Allen attended Lakeside School, where he befriended Bill Gates' Here, does 'Allen' stand for 'Paul Allen'? Yes or no?  Yes\\n'A dog named Teddy ran to his owner Jane. Jane loves her dog.' Here, does 'Jane' stand for 'Teddy'? Yes or no?  No\\n'I bought 3 bottles of wine today, when I went to John Doe’s store' Here, does 'John Doe' stand for 'I'? Yes or no?  No\\n'Vasco told me yesterday that is his final exam went pretty well. Vasco worked really hard.' Here, does 'Vasco' stand for 'Vasco'? Yes or no?  Yes\\n'Her car was so fast, that it went past the speed limit' Here, does 'it' stand for 'Her car'? Yes or no?  Yes\\n'Some of our colleagues are going to be supportive. These kinds of people will earn our gratitude' Here, does 'our gratitude' stand for 'Some of our colleagues'? Yes or no?  No\\n'Barack Obama won the midterm elections, so he was in office for 2 terms' Here, does 'he' stand for 'Barack Obama'? Yes or no?  Yes\\n'Our neighbors dislike the music. If they are angry, the cops will show up soon' Here, does 'the cops' stand for 'they'? Yes or no?  No\\n\",\n","  \"'Anna told her friends that she was about to go to college.' In the passage above, can 'she' be replaced by 'Anna'? Yes or no? Yes\\n'Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party' In the passage above, can 'her' be replaced by 'Eva'? Yes or no? No\\n'Paul Allen was born on Jan 21, 1953. Allen attended Lakeside School, where he befriended Bill Gates' In the passage above, can 'Allen' be replaced by 'Paul Allen'? Yes or no? Yes\\n'A dog named Teddy ran to his owner Jane. Jane loves her dog.' In the passage above, can 'Jane' be replaced by 'Teddy'? Yes or no? No\\n'I bought 3 bottles of wine today, when I went to John Doe’s store' In the passage above, can 'John Doe' be replaced by 'I'? Yes or no? No\\n'Vasco told me yesterday that is his final exam went pretty well. Vasco worked really hard.' In the passage above, can 'Vasco' be replaced by 'Vasco'? Yes or no? Yes\\n'Her car was so fast, that it went past the speed limit' In the passage above, can 'it' be replaced by 'Her car'? Yes or no? Yes\\n'Some of our colleagues are going to be supportive. These kinds of people will earn our gratitude' In the passage above, can 'our gratitude' be replaced by 'Some of our colleagues'? Yes or no? No\\n'Barack Obama won the midterm elections, so he was in office for 2 terms' In the passage above, can 'he' be replaced by 'Barack Obama'? Yes or no? Yes\\n'Our neighbors dislike the music. If they are angry, the cops will show up soon' In the passage above, can 'the cops' be replaced by 'they'? Yes or no? No\\n\",\n","  \"'Anna told her friends that she was about to go to college.' I think 'she' means 'Anna'. Yes or no? Yes\\n'Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party' I think 'her' means 'Eva'. Yes or no? No\\n'Paul Allen was born on Jan 21, 1953. Allen attended Lakeside School, where he befriended Bill Gates' I think 'Allen' means 'Paul Allen'. Yes or no? Yes\\n'A dog named Teddy ran to his owner Jane. Jane loves her dog.' I think 'Jane' means 'Teddy'. Yes or no? No\\n'I bought 3 bottles of wine today, when I went to John Doe’s store' I think 'John Doe' means 'I'. Yes or no? No\\n'Vasco told me yesterday that is his final exam went pretty well. Vasco worked really hard.' I think 'Vasco' means 'Vasco'. Yes or no? Yes\\n'Her car was so fast, that it went past the speed limit' I think 'it' means 'Her car'. Yes or no? Yes\\n'Some of our colleagues are going to be supportive. These kinds of people will earn our gratitude' I think 'our gratitude' means 'Some of our colleagues'. Yes or no? No\\n'Barack Obama won the midterm elections, so he was in office for 2 terms' I think 'he' means 'Barack Obama'. Yes or no? Yes\\n'Our neighbors dislike the music. If they are angry, the cops will show up soon' I think 'the cops' means 'they'. Yes or no? No\\n\"],\n"," 'superglue': [\"'Mark told Pete many lies about himself, which Pete included in his book. He should have been more skeptical.' In previous sentences, does 'He' refer to 'Mark'? Yes or no? No\\n'The mothers of Arthur and Celeste have come to the town to fetch them. They are very happy to have them back, but they scold them just the same because they ran away.' In previous sentences, does 'them' refer to 'mothers'? Yes or no? No\\n'Mark was close to Mr. Singer 's heels. He heard him calling for the captain, promising him, in the jargon everyone talked that night, that not one thing should be damaged on the ship except only the ammunition, but the captain and all his crew had best stay in the cabin until the work was over' In previous sentences, does 'He' refer to 'Mr. Singer'? Yes or no? No\\n'The pony behaved well, sir, and showed no vice; but at last he just threw up his heels and tipped the young gentleman into the thorn hedge. He wanted me to help him out, but I hope you will excuse me, sir, I did not feel inclined to do so.' In previous sentences, does 'He' refer to 'young gentleman'? Yes or no? Yes\\n'I poured water from the bottle into the cup until it was full.' In previous sentences, does 'it' refer to 'the cup'? Yes or no? Yes\\n'Dan had to stop Bill from toying with the injured bird. He is very compassionate.' In previous sentences, does 'He' refer to 'Dan'? Yes or no? Yes\\n'Sam Goodman 's biography of the Spartan general Xenophanes conveys a vivid sense of the difficulties he faced in his childhood.' In previous sentences, does 'he' refer to 'Goodman'? Yes or no? No\\n'Pam's parents came home and found her having sex with her boyfriend, Paul. They were furious about it.' In previous sentences, does 'They' refer to 'Pam's parents'? Yes or no? Yes\\n'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very hurt.' In previous sentences, does 'He' refer to 'Bob'? Yes or no? Yes\\n'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very ungrateful.' In previous sentences, does 'He' refer to 'Bob'? Yes or no? No\\n\",\n","  \"'Mark told Pete many lies about himself, which Pete included in his book. He should have been more skeptical.' Here, by 'He' they mean 'Mark'? Yes or no? No\\n'The mothers of Arthur and Celeste have come to the town to fetch them. They are very happy to have them back, but they scold them just the same because they ran away.' Here, by 'them' they mean 'mothers'? Yes or no? No\\n'Mark was close to Mr. Singer 's heels. He heard him calling for the captain, promising him, in the jargon everyone talked that night, that not one thing should be damaged on the ship except only the ammunition, but the captain and all his crew had best stay in the cabin until the work was over' Here, by 'He' they mean 'Mr. Singer'? Yes or no? No\\n'The pony behaved well, sir, and showed no vice; but at last he just threw up his heels and tipped the young gentleman into the thorn hedge. He wanted me to help him out, but I hope you will excuse me, sir, I did not feel inclined to do so.' Here, by 'He' they mean 'young gentleman'? Yes or no? Yes\\n'I poured water from the bottle into the cup until it was full.' Here, by 'it' they mean 'the cup'? Yes or no? Yes\\n'Dan had to stop Bill from toying with the injured bird. He is very compassionate.' Here, by 'He' they mean 'Dan'? Yes or no? Yes\\n'Sam Goodman 's biography of the Spartan general Xenophanes conveys a vivid sense of the difficulties he faced in his childhood.' Here, by 'he' they mean 'Goodman'? Yes or no? No\\n'Pam's parents came home and found her having sex with her boyfriend, Paul. They were furious about it.' Here, by 'They' they mean 'Pam's parents'? Yes or no? Yes\\n'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very hurt.' Here, by 'He' they mean 'Bob'? Yes or no? Yes\\n'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very ungrateful.' Here, by 'He' they mean 'Bob'? Yes or no? No\\n\",\n","  \"'Mark told Pete many lies about himself, which Pete included in his book. He should have been more skeptical.' Here, does 'He' stand for 'Mark'? Yes or no?  No\\n'The mothers of Arthur and Celeste have come to the town to fetch them. They are very happy to have them back, but they scold them just the same because they ran away.' Here, does 'them' stand for 'mothers'? Yes or no?  No\\n'Mark was close to Mr. Singer 's heels. He heard him calling for the captain, promising him, in the jargon everyone talked that night, that not one thing should be damaged on the ship except only the ammunition, but the captain and all his crew had best stay in the cabin until the work was over' Here, does 'He' stand for 'Mr. Singer'? Yes or no?  No\\n'The pony behaved well, sir, and showed no vice; but at last he just threw up his heels and tipped the young gentleman into the thorn hedge. He wanted me to help him out, but I hope you will excuse me, sir, I did not feel inclined to do so.' Here, does 'He' stand for 'young gentleman'? Yes or no?  Yes\\n'I poured water from the bottle into the cup until it was full.' Here, does 'it' stand for 'the cup'? Yes or no?  Yes\\n'Dan had to stop Bill from toying with the injured bird. He is very compassionate.' Here, does 'He' stand for 'Dan'? Yes or no?  Yes\\n'Sam Goodman 's biography of the Spartan general Xenophanes conveys a vivid sense of the difficulties he faced in his childhood.' Here, does 'he' stand for 'Goodman'? Yes or no?  No\\n'Pam's parents came home and found her having sex with her boyfriend, Paul. They were furious about it.' Here, does 'They' stand for 'Pam's parents'? Yes or no?  Yes\\n'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very hurt.' Here, does 'He' stand for 'Bob'? Yes or no?  Yes\\n'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very ungrateful.' Here, does 'He' stand for 'Bob'? Yes or no?  No\\n\",\n","  \"'Mark told Pete many lies about himself, which Pete included in his book. He should have been more skeptical.' In the passage above, can 'He' be replaced by 'Mark'? Yes or no? No\\n'The mothers of Arthur and Celeste have come to the town to fetch them. They are very happy to have them back, but they scold them just the same because they ran away.' In the passage above, can 'them' be replaced by 'mothers'? Yes or no? No\\n'Mark was close to Mr. Singer 's heels. He heard him calling for the captain, promising him, in the jargon everyone talked that night, that not one thing should be damaged on the ship except only the ammunition, but the captain and all his crew had best stay in the cabin until the work was over' In the passage above, can 'He' be replaced by 'Mr. Singer'? Yes or no? No\\n'The pony behaved well, sir, and showed no vice; but at last he just threw up his heels and tipped the young gentleman into the thorn hedge. He wanted me to help him out, but I hope you will excuse me, sir, I did not feel inclined to do so.' In the passage above, can 'He' be replaced by 'young gentleman'? Yes or no? Yes\\n'I poured water from the bottle into the cup until it was full.' In the passage above, can 'it' be replaced by 'the cup'? Yes or no? Yes\\n'Dan had to stop Bill from toying with the injured bird. He is very compassionate.' In the passage above, can 'He' be replaced by 'Dan'? Yes or no? Yes\\n'Sam Goodman 's biography of the Spartan general Xenophanes conveys a vivid sense of the difficulties he faced in his childhood.' In the passage above, can 'he' be replaced by 'Goodman'? Yes or no? No\\n'Pam's parents came home and found her having sex with her boyfriend, Paul. They were furious about it.' In the passage above, can 'They' be replaced by 'Pam's parents'? Yes or no? Yes\\n'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very hurt.' In the passage above, can 'He' be replaced by 'Bob'? Yes or no? Yes\\n'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very ungrateful.' In the passage above, can 'He' be replaced by 'Bob'? Yes or no? No\\n\",\n","  \"'Mark told Pete many lies about himself, which Pete included in his book. He should have been more skeptical.' I think 'He' means 'Mark'. Yes or no? No\\n'The mothers of Arthur and Celeste have come to the town to fetch them. They are very happy to have them back, but they scold them just the same because they ran away.' I think 'them' means 'mothers'. Yes or no? No\\n'Mark was close to Mr. Singer 's heels. He heard him calling for the captain, promising him, in the jargon everyone talked that night, that not one thing should be damaged on the ship except only the ammunition, but the captain and all his crew had best stay in the cabin until the work was over' I think 'He' means 'Mr. Singer'. Yes or no? No\\n'The pony behaved well, sir, and showed no vice; but at last he just threw up his heels and tipped the young gentleman into the thorn hedge. He wanted me to help him out, but I hope you will excuse me, sir, I did not feel inclined to do so.' I think 'He' means 'young gentleman'. Yes or no? Yes\\n'I poured water from the bottle into the cup until it was full.' I think 'it' means 'the cup'. Yes or no? Yes\\n'Dan had to stop Bill from toying with the injured bird. He is very compassionate.' I think 'He' means 'Dan'. Yes or no? Yes\\n'Sam Goodman 's biography of the Spartan general Xenophanes conveys a vivid sense of the difficulties he faced in his childhood.' I think 'he' means 'Goodman'. Yes or no? No\\n'Pam's parents came home and found her having sex with her boyfriend, Paul. They were furious about it.' I think 'They' means 'Pam's parents'. Yes or no? Yes\\n'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very hurt.' I think 'He' means 'Bob'. Yes or no? Yes\\n'Bob paid for Charlie 's college education, but now Charlie acts as though it never happened. He is very ungrateful.' I think 'He' means 'Bob'. Yes or no? No\\n\"]}"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["prefix_types = [\"simple\",\"superglue\",\"ecb\"]\n","all_prefix = [prefixes_simple, prefixes_super_glue, prefixes_ecb]\n","# all_prefix = [prefixes_simple]\n","prefix_dict = {}\n","\n","for i, prefixes in enumerate(all_prefix):\n","    generators = []\n","    current_prefixes = []\n","\n","    for prefix in prefixes:\n","        # print(f\"Getting generator for prefix: -> {prefix}\")\n","        current_prefixes.append(prefix)\n","\n","    prefix_dict[prefix_types[i]] = current_prefixes\n","\n","prefix_dict\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226,"referenced_widgets":["12eadf02f3154471bf0b089db9f157ca","8ed21e6b7e6444b7bdd69e5b0acce668","6d74783bee424a05a16a3e916a9f58fc","ed79044a702a40aea20564aa55616649","331d34cd01d244b0befdb5e2f0237fb1","549ac1612d5e43c49f27ed14537bce9f","4b5561a417614ff386197a5c60206dfa","456d7bc8a58f4c29a6749a596106d3b8","f380177e174c494b8adf267b5d2db425","a84adfc40c5747f69ac754134c9531c9","5aafc015755a4a04b4fd3a18312d0953","556702c265ac4d1ebb3bb535d85d7bb8","801a17ebd59844a89b55abc02457362b","1c939919b27846aab2049394a001b57c","8eece1a2d06a4109a946d23f0d3284f0","d7e76ec5a5bc4c55ace3c541c61c634a","49c801131a0d4924a4326dd1cca41e69","3dcfd30e46f6419484a51957294af60d","d83ecafccc6e4656af255f009c4be49f","20e88e10368d4f30a0d9a53dce9ee764","4cb6008b3d934ab9859c9ff65855c3ec","200c4fbc97c14485a87d97344c98f8c2","47f1da8d5e8a4292b5b10cdc31e093da","0e72f3cda9754d2781542425202e20b3","a8d458347d26491ca1edbcf7c2fe8910","8c41bd61f17e4a55a19383bd416ac16f","25b650b1b1ce41ed8ebd5e5ca6fc32c3","c41f180dfb7249aa9cbea14ab376917c","fbcc518d08ee431086dcb9ff888c2b9d","860d2eeae7484934a0269b12a578500a","93e95d24eec54c20920f2020b2629125","25a6f2b76c5b46158c39c580d72d93b0","e220af41a2a6467db7871297e4add480","11fa08ccd487447c82486af7c8c63113","fbdaeb25b94a445c932cc4a1e868387c","d3877a6f8d9540d796e7627fb7c5ded4","da974f946de745c08061294b590c38b5","e745fcb8cbc047f3b30f4f8ea23fd869","bca3917920f0484bbc1ee4f6a7b5954f","b4d52aa0f5f341b5a28a6b84a690183f","7f2f20a9949140f982d61f0eaf9a7567","c73894249dc64e239c5d7e923717f31c","e1d9e5d399e34f06b5b7a2679f0badad","a25d22e0a61d4c8eb6f37edc2cdb2175","19ebd68ba76745e1b4a5cc8bc134a468","465c9f72c2864025b5ae458bc5248d8e","d0470b6ed0c14f5382ad59a3c9a4ce45","8b3f7562be7745f89b4a79759a24aef8","2bdd58407d624672a7999133c59d167e","904f90485644422096befb8edbe53cfb","b2055aff75ab40fc866376c779c45946","6ba70ade83ad4e9eb7071854136ff58f","a55c6c45441346209b2d827538cf7eef","416bae8a67d34d5aadff383c8462ef6f","f5abd1e9a96940efa82e3ba92fa44fc8","6ff2cbfc671a44199990f79f9ff183da","3664081495e643a98434b4d4f9463a95","e7d3d6e1bb8c4e11a6539132faa89996","629bebe27de94f52ba9f32e8be9f6f97","886bf2dac0e24035a6846aae82ae6073","3aecdfa18dd7409aa45ab88ea528e979","213d94c2e7634d3382df4ec0aa6eda0d","17675d5a53d64952a4644e0133a65537","310c472a313d47779ce5dcd836a92f94","bb42e8f159f64ef3bc16556b42f96ff5","f30860e5b4e741239a027b1b6f94ed10"]},"executionInfo":{"elapsed":32062,"status":"ok","timestamp":1645021079550,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"EoL8QG1umqrh","outputId":"58ba8c94-3e70-4dc7-d812-1ea882a78024"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12eadf02f3154471bf0b089db9f157ca","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"556702c265ac4d1ebb3bb535d85d7bb8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47f1da8d5e8a4292b5b10cdc31e093da","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/560 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11fa08ccd487447c82486af7c8c63113","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19ebd68ba76745e1b4a5cc8bc134a468","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ff2cbfc671a44199990f79f9ff183da","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7f2591082c50>\n"]}],"source":["generator = pipeline('text-generation', model=f'EleutherAI/gpt-neo-{NEO_SIZE}', return_full_text=False, \n","                               device=torch.cuda.current_device()) \n","print(generator)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VGDcSQQpnxv2"},"source":["# Experiment\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1645021083535,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"},"user_tz":-60},"id":"2c0ZoenY3Szv","outputId":"fc5825c4-fa92-4e28-8690-24c679548c76"},"outputs":[{"name":"stdout","output_type":"stream","text":["' An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday.  The tremor struck an area around the town of Dargahan on Qeshm island, at the entrance to the Persian Gulf, injuring five people and damaging buildings. ' Here, does 'an area around the town of Dargahan on Qeshm island , at the entrance to the Persian Gulf' stand for 'Qeshm island off Iran 's southern coast'? Yes or no?  Yes\n","'Five Wounded by Quake in Southern Iran  An earthquake measuring 5.6 on the Richter scale jolted Qeshm island off Iran's southern coast on Sunday, followed by several aftershocks on Monday. ' Here, does 'Richter scale' stand for '5.6'? Yes or no?  No\n","' Ten dead in southern Iran quake  A powerful earthquake has hit southern Iran, killing at least 10 people, injuring dozens more and damaging several villages, officials say. ' Here, does 'people' stand for 'Ten'? Yes or no?  Yes\n","' Last Updated: Monday, 28 November 2005, 02: 24 GMT  Ten dead in southern Iran quake ' Here, does 'Ten' stand for 'Monday , 28 November 2005 , 02 : 24 GMT'? Yes or no?  No\n","' Aftershocks jolt Iran's Qeshm island, death toll rises to 10  The sixth aftershock shook this southern Iranian island in the Persian Gulf on Monday as death toll from a strong earthquake a day before rose to 10. ' Here, does 'southern Iranian island in the Persian Gulf' stand for 'Iran 's Qeshm island'? Yes or no?  Yes\n","' 11/28/05  Aftershocks jolt Iran's Qeshm island, death toll rises to 10 ' Here, does 'Iran 's Qeshm island' stand for '11/28/05'? Yes or no?  No\n","'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' Here, does 'on the outskirts of Dargahan , a small town on the island' stand for 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province'? Yes or no?  Yes\n","'A strong 5.6-magnitude earthquake jolted part of Qeshm island in the Gulf off Iran's southern Hormozgan province at 17:06 pm (1336 GMT) on Sunday, state television reported, cited by AFP.  According to the student ISNA news agency, the quake on the outskirts of Dargahan, a small town on the island, injured two people. ' Here, does 'part of Qeshm island in the Gulf off Iran 's southern Hormozgan province' stand for '5.6-magnitude'? Yes or no?  No\n","' Nov 28, 2005  Iranian rescue workers handed out blankets, food and water Monday to survivors of a powerful earthquake on a Gulf island that killed 10 people and forced villagers to spend the night in tents. ' Here, does 'villagers' stand for 'survivors'? Yes or no?  Yes\n","'http://www.terradaily.com/news/disaster-management-05zzzzzc. html  Iran Villagers Shelter In Tents After Killer Quake ' Here, does 'In Tents' stand for 'Villagers'? Yes or no?  No\n","\n","examples using prefix\n"]}],"source":["prefix_test = prefix_dict['ecb'][i] if n_examples > 0 else \"\"\n","print(prefix_test)\n","\n","if prefix_test == \"\":\n","  print(\"dwdfsvc\")\n","else:\n","  print(\"examples using prefix\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"stM_RtRLMNPH"},"outputs":[],"source":["def make_prediction_helper(text, pair, template, prefix, generator, temp, n):\n","    pred_sum = 0\n","    count = 0\n","    mention_pair = [pair[0][\"mention\"], pair[1][\"mention\"]]\n","    for i in range(n):\n","        prompt = generate_prompt(template, text, mention_pair)\n","        if prefix == \"\":\n","          pred = generator(prompt, max_length=1, num_return_sequences=1, temperature = temp)[0][\"generated_text\"]\n","        else:\n","          pred = generator(prompt, max_length=1, prefix=prefix, num_return_sequences=1, temperature = temp)[0][\"generated_text\"]\n","\n","        pred = pred.strip().lower()\n","        if pred == \"yes\":\n","            pred_sum += 1\n","            count += 1\n","        elif pred == \"no\":\n","            count += 1\n","        else:\n","            print(pred)\n","            \n","    if count == 0:\n","        pred_sum = -1\n","    \n","    return pred_sum,count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aN2oqYlnVSMB"},"outputs":[],"source":["def make_prediction(samples, templates, prefixer, generator, temp, n=5):\n","    templates_results = []\n","    for i, template in enumerate(templates):\n","        # generator = generators[i]\n","        # prefix = prefixer[i]\n","        prefix = prefixer[i] if n_examples > 0 else \"\"\n","\n","        results = []\n","        for i in tqdm(range(len(samples))):\n","            _, text, pair, _ = samples[i]\n","            pred_sum, count = make_prediction_helper(text, pair, template, prefix, generator, temp, n)           \n","            results.append((pred_sum, count))\n","        templates_results.append(results)\n","        clear_output()\n","    print(len(templates_results),len(templates_results[0]))\n","    return templates_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xyvFiiUZcHO"},"outputs":[],"source":["def annotate(data, prefix_type, repeated_n, prefixer, generator, templates, temp):\n","    prompt_column_names = [f\"Prompt {i+1}\" for i in range(len(templates))]\n","    for doc_name in data:\n","        text, toks, mentions, clusters = data[doc_name]\n","        doc = docDataset(doc_name,text, toks, clusters, mentions)\n","        doc.create_mention_pairs()\n","        samples = doc.get_experiment_samples()\n","        res = make_prediction(samples, templates, prefixer, generator, temp, repeated_n)\n","        \n","        result_df = pd.DataFrame(res).T\n","        result_df.columns = prompt_column_names\n","        result_df[\"doc_name\"] = doc_name\n","        sample_df = pd.DataFrame(samples, columns = [\"sent_idx\",\"text\",\"mention pair\",\"label\"])\n","        result_df = pd.concat([result_df, sample_df], axis = 1)\n","        \n","\n","        output_file = f\"{root_path}/Results/GPT-NEO/GPT_NEO-{NEO_SAVE_NAME}_gold_mentions_{temp}_temperature_{n_examples}-shots_{prefix_type}_prefix_{repeated_n}-repeats.csv\"\n","        result_df.to_csv(output_file, index = False, mode = \"a\")\n","    \n","    print(f\"{prefix_type}_prefix_{repeated_n}-repeats Results saved\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tW5n1Yf6c0ee"},"outputs":[],"source":["def experiments(data, prefix_types, repeated_ns, generator, templates, temperatures):\n","    for temp in tqdm(temperatures):\n","      for prefix_type in prefix_types:\n","          for n in repeated_ns:\n","              prefixer = prefix_dict[prefix_type]\n","              annotate(data, prefix_type, n, prefixer, generator, templates, temp)\n","    print(\"Experiments Completed.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"WmbbRcFNYkqj","outputId":"298b99dc-56fe-44e0-b951-d152fb423b5b"},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/396 [00:00<?, ?it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 539, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 539, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 539, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 539, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 539, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  0%|          | 1/396 [00:00<00:53,  7.42it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 521, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 521, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 521, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 521, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 521, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  1%|          | 2/396 [00:00<00:52,  7.50it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 522, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 522, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 522, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 522, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 522, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  1%|          | 3/396 [00:00<00:52,  7.55it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 519, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 519, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 519, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 519, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 519, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  1%|          | 4/396 [00:00<00:52,  7.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  1%|▏         | 5/396 [00:00<00:52,  7.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  2%|▏         | 6/396 [00:00<00:52,  7.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  2%|▏         | 7/396 [00:00<00:52,  7.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  2%|▏         | 8/396 [00:01<00:51,  7.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  2%|▏         | 9/396 [00:01<00:51,  7.51it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 533, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  3%|▎         | 10/396 [00:01<00:51,  7.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  3%|▎         | 11/396 [00:01<00:51,  7.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  3%|▎         | 12/396 [00:01<00:51,  7.47it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  3%|▎         | 13/396 [00:01<00:51,  7.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  4%|▎         | 14/396 [00:01<00:50,  7.51it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  4%|▍         | 15/396 [00:02<00:50,  7.53it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  4%|▍         | 16/396 [00:02<00:50,  7.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  4%|▍         | 17/396 [00:02<00:50,  7.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  5%|▍         | 18/396 [00:02<00:50,  7.46it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  5%|▍         | 19/396 [00:02<00:50,  7.48it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  5%|▌         | 20/396 [00:02<00:50,  7.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  5%|▌         | 21/396 [00:02<00:50,  7.38it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 532, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  6%|▌         | 22/396 [00:02<00:50,  7.43it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 530, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  6%|▌         | 23/396 [00:03<00:50,  7.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  6%|▌         | 24/396 [00:03<00:49,  7.45it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 531, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  6%|▋         | 25/396 [00:03<00:49,  7.49it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  7%|▋         | 26/396 [00:03<00:49,  7.41it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  7%|▋         | 27/396 [00:03<00:50,  7.37it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  7%|▋         | 28/396 [00:03<00:49,  7.36it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  7%|▋         | 29/396 [00:03<00:49,  7.35it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  8%|▊         | 30/396 [00:04<00:49,  7.33it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  8%|▊         | 31/396 [00:04<00:50,  7.27it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  8%|▊         | 32/396 [00:04<00:49,  7.30it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  8%|▊         | 33/396 [00:04<00:50,  7.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  9%|▊         | 34/396 [00:04<00:50,  7.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  9%|▉         | 35/396 [00:04<00:50,  7.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  9%|▉         | 36/396 [00:04<00:50,  7.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n","  9%|▉         | 37/396 [00:05<00:49,  7.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 10%|▉         | 38/396 [00:05<00:49,  7.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 10%|▉         | 39/396 [00:05<00:49,  7.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 10%|█         | 40/396 [00:05<00:49,  7.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 10%|█         | 41/396 [00:05<00:49,  7.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 11%|█         | 42/396 [00:05<00:49,  7.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 11%|█         | 43/396 [00:05<00:49,  7.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 11%|█         | 44/396 [00:05<00:49,  7.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 11%|█▏        | 45/396 [00:06<00:49,  7.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 12%|█▏        | 46/396 [00:06<00:49,  7.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 12%|█▏        | 47/396 [00:06<00:49,  7.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 12%|█▏        | 48/396 [00:06<00:48,  7.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 12%|█▏        | 49/396 [00:06<00:48,  7.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 13%|█▎        | 50/396 [00:06<00:48,  7.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 13%|█▎        | 51/396 [00:06<00:48,  7.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 13%|█▎        | 52/396 [00:07<00:48,  7.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 13%|█▎        | 53/396 [00:07<00:48,  7.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 14%|█▎        | 54/396 [00:07<00:47,  7.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 14%|█▍        | 55/396 [00:07<00:47,  7.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 14%|█▍        | 56/396 [00:07<00:47,  7.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 14%|█▍        | 57/396 [00:07<00:47,  7.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 15%|█▍        | 58/396 [00:07<00:46,  7.23it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 15%|█▍        | 59/396 [00:08<00:46,  7.26it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 15%|█▌        | 60/396 [00:08<00:46,  7.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 15%|█▌        | 61/396 [00:08<00:46,  7.25it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 16%|█▌        | 62/396 [00:08<00:46,  7.22it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 16%|█▌        | 63/396 [00:08<00:46,  7.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 16%|█▌        | 64/396 [00:08<00:46,  7.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 16%|█▋        | 65/396 [00:08<00:46,  7.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 17%|█▋        | 66/396 [00:09<00:45,  7.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 17%|█▋        | 67/396 [00:09<00:45,  7.17it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 17%|█▋        | 68/396 [00:09<00:45,  7.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 17%|█▋        | 69/396 [00:09<00:45,  7.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 18%|█▊        | 70/396 [00:09<00:45,  7.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 18%|█▊        | 71/396 [00:09<00:45,  7.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 18%|█▊        | 72/396 [00:09<00:45,  7.14it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 18%|█▊        | 73/396 [00:10<00:45,  7.16it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 19%|█▊        | 74/396 [00:10<00:44,  7.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 19%|█▉        | 75/396 [00:10<00:44,  7.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 559, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 19%|█▉        | 76/396 [00:10<00:44,  7.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 19%|█▉        | 77/396 [00:10<00:44,  7.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 20%|█▉        | 78/396 [00:10<00:44,  7.18it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 553, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 20%|█▉        | 79/396 [00:10<00:44,  7.20it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 20%|██        | 80/396 [00:10<00:43,  7.21it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 20%|██        | 81/396 [00:11<00:43,  7.19it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 21%|██        | 82/396 [00:11<00:44,  7.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 21%|██        | 83/396 [00:11<00:44,  7.11it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 21%|██        | 84/396 [00:11<00:43,  7.13it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 21%|██▏       | 85/396 [00:11<00:43,  7.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 22%|██▏       | 86/396 [00:11<00:43,  7.06it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 22%|██▏       | 87/396 [00:11<00:43,  7.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 22%|██▏       | 88/396 [00:12<00:43,  7.10it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 22%|██▏       | 89/396 [00:12<00:43,  7.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 23%|██▎       | 90/396 [00:12<00:43,  7.07it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 560, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 23%|██▎       | 91/396 [00:12<00:42,  7.09it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 23%|██▎       | 92/396 [00:12<00:42,  7.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 555, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 23%|██▎       | 93/396 [00:12<00:42,  7.08it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 554, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 24%|██▎       | 94/396 [00:12<00:42,  7.12it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 556, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","\n"," 24%|██▍       | 95/396 [00:13<00:42,  7.15it/s]\u001b[ASetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 552, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 552, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 552, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 552, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Input length of input_ids is 552, but ``max_length`` is set to 483. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"]}],"source":["temperatures = [i/5 for i in range(1, 6)]\n","\n","\n","experiments(dev, prefix_types, [5], generator, templates, temperatures)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeP-fy1ske7v"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuIC4OaekpzH"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"GPT_NEO_temprature.ipynb","provenance":[{"file_id":"1fyJaTU8ZCuTlYiJSqxxVjJHAbnG-wG2a","timestamp":1637594718782},{"file_id":"15iBdKhET_gFQsV-ZwPqPJMn4yLZMhH2r","timestamp":1637566539352}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01115ca094aa4e219c152c479fa1f13b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"0884e03afa97438e9332d1c9c7dd3d8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a586a5b02d94f98bdd43b8968a008c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93360276fb57431bbbce2f632d52f0d3","IPY_MODEL_c85e7735da3740b39c3ec5aa97a170b7","IPY_MODEL_59ce08cf1a0744a59a909c8ca0f1479d"],"layout":"IPY_MODEL_40b86517f54c4984a97f2c279a4a6aa6"}},"0e72f3cda9754d2781542425202e20b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c41f180dfb7249aa9cbea14ab376917c","placeholder":"​","style":"IPY_MODEL_fbcc518d08ee431086dcb9ff888c2b9d","value":"Downloading: 100%"}},"0fad219c4d6e46f5a504664ce4246e4b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"11fa08ccd487447c82486af7c8c63113":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbdaeb25b94a445c932cc4a1e868387c","IPY_MODEL_d3877a6f8d9540d796e7627fb7c5ded4","IPY_MODEL_da974f946de745c08061294b590c38b5"],"layout":"IPY_MODEL_e745fcb8cbc047f3b30f4f8ea23fd869"}},"12eadf02f3154471bf0b089db9f157ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ed21e6b7e6444b7bdd69e5b0acce668","IPY_MODEL_6d74783bee424a05a16a3e916a9f58fc","IPY_MODEL_ed79044a702a40aea20564aa55616649"],"layout":"IPY_MODEL_331d34cd01d244b0befdb5e2f0237fb1"}},"14372532977a447a9cbe99676419a1bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_a14d932614db4cc9a320f6a2c1e89fb9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb1b818f3c254961a2a166c0c2d8b5c3","value":1}},"17675d5a53d64952a4644e0133a65537":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19ebd68ba76745e1b4a5cc8bc134a468":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_465c9f72c2864025b5ae458bc5248d8e","IPY_MODEL_d0470b6ed0c14f5382ad59a3c9a4ce45","IPY_MODEL_8b3f7562be7745f89b4a79759a24aef8"],"layout":"IPY_MODEL_2bdd58407d624672a7999133c59d167e"}},"1c90873b151e46d695de01da82940ed9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c939919b27846aab2049394a001b57c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d83ecafccc6e4656af255f009c4be49f","max":526017373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20e88e10368d4f30a0d9a53dce9ee764","value":526017373}},"200c4fbc97c14485a87d97344c98f8c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20e88e10368d4f30a0d9a53dce9ee764":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"213d94c2e7634d3382df4ec0aa6eda0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22d02623765940b48a06fd7f5fe51cff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23c7444d8bd2482e9324fe06fd93904d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"257785ac42914a62904b89a986fe5bcf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25a6f2b76c5b46158c39c580d72d93b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25b650b1b1ce41ed8ebd5e5ca6fc32c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"260edfed9cec411db524193e3b96aa7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a29a397fd63d475a8fa26e97d0c78150","IPY_MODEL_14372532977a447a9cbe99676419a1bf","IPY_MODEL_5774486f05b0469eac980223644936ab"],"layout":"IPY_MODEL_1c90873b151e46d695de01da82940ed9"}},"29b42f6186bb481bb854ad0f0b185255":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bdd58407d624672a7999133c59d167e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"310c472a313d47779ce5dcd836a92f94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"331d34cd01d244b0befdb5e2f0237fb1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3664081495e643a98434b4d4f9463a95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3aecdfa18dd7409aa45ab88ea528e979","placeholder":"​","style":"IPY_MODEL_213d94c2e7634d3382df4ec0aa6eda0d","value":"Downloading: 100%"}},"3857c662ab5448b3a895e35174717109":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3aecdfa18dd7409aa45ab88ea528e979":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dcfd30e46f6419484a51957294af60d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40b86517f54c4984a97f2c279a4a6aa6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"416bae8a67d34d5aadff383c8462ef6f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4341a76c5c744ff99832df365a9bd096":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"456d7bc8a58f4c29a6749a596106d3b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"463563e2389a4e4cab6344b7a0bf73e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"465c9f72c2864025b5ae458bc5248d8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_904f90485644422096befb8edbe53cfb","placeholder":"​","style":"IPY_MODEL_b2055aff75ab40fc866376c779c45946","value":"Downloading: 100%"}},"4703848be1a44c8e9fef6a8337874b48":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"474e63ea64c44f6bbda84667d6a74036":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_911dd7b8186d49a09e568c60d33ddabe","placeholder":"​","style":"IPY_MODEL_23c7444d8bd2482e9324fe06fd93904d","value":" 3/3 [00:00&lt;00:00, 88.23it/s]"}},"477aa4822a364c398b17b9eb7c0a1b21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7d5586a137b4a318fc0e7160ae13613","placeholder":"​","style":"IPY_MODEL_caebeae14d25422f9f2a83e88981ebe0","value":"Downloading: "}},"47f1da8d5e8a4292b5b10cdc31e093da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e72f3cda9754d2781542425202e20b3","IPY_MODEL_a8d458347d26491ca1edbcf7c2fe8910","IPY_MODEL_8c41bd61f17e4a55a19383bd416ac16f"],"layout":"IPY_MODEL_25b650b1b1ce41ed8ebd5e5ca6fc32c3"}},"49afecb48bc24563aecbcb4b4759ddf5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8edb074b313b48c0ab6e7b33229b7b14","placeholder":"​","style":"IPY_MODEL_f4def5ba293943d695f1c53a3e966398","value":"Downloading: "}},"49c801131a0d4924a4326dd1cca41e69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b5561a417614ff386197a5c60206dfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cb6008b3d934ab9859c9ff65855c3ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d626c20ef854689be9260686a96f967":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ff3923570b04a23946564e7a04a4eeb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_770946fdcb274169ae09d34dac3797fa","placeholder":"​","style":"IPY_MODEL_3857c662ab5448b3a895e35174717109","value":""}},"549ac1612d5e43c49f27ed14537bce9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"556702c265ac4d1ebb3bb535d85d7bb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_801a17ebd59844a89b55abc02457362b","IPY_MODEL_1c939919b27846aab2049394a001b57c","IPY_MODEL_8eece1a2d06a4109a946d23f0d3284f0"],"layout":"IPY_MODEL_d7e76ec5a5bc4c55ace3c541c61c634a"}},"5774486f05b0469eac980223644936ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4703848be1a44c8e9fef6a8337874b48","placeholder":"​","style":"IPY_MODEL_b6ec91c0c92b4c0faaed75d0fb393e92","value":" 0/0 [00:00&lt;?, ? examples/s]"}},"59ce08cf1a0744a59a909c8ca0f1479d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3c22cbc812947f38bcf9be8fe1d4763","placeholder":"​","style":"IPY_MODEL_4341a76c5c744ff99832df365a9bd096","value":" 0/0 [00:00&lt;?, ? examples/s]"}},"5aafc015755a4a04b4fd3a18312d0953":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b54b9c501cc4770abb8fa3faa7f94e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_257785ac42914a62904b89a986fe5bcf","placeholder":"​","style":"IPY_MODEL_ece9a2ccf8594878becb4fa531fb400c","value":" 29.9k/? [00:00&lt;00:00, 972kB/s]"}},"5ecb25da55ac4caa8738e0f237106e6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"629bebe27de94f52ba9f32e8be9f6f97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb42e8f159f64ef3bc16556b42f96ff5","placeholder":"​","style":"IPY_MODEL_f30860e5b4e741239a027b1b6f94ed10","value":" 357/357 [00:00&lt;00:00, 14.7kB/s]"}},"642e62327f09481cbb3eaee393bf4c47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72ab2c1d08de4c62b6aeccba61c7fb5f","placeholder":"​","style":"IPY_MODEL_ba22aebfdb544aad83130732effa26d5","value":" 32.8k/32.8k [00:00&lt;00:00, 106kB/s]"}},"664eb6dd34ba4c0dac272a8ac79b6b03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9b9e81a3570409ba48d907f878950cb","max":9472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29b42f6186bb481bb854ad0f0b185255","value":9472}},"68175a3852084de79743ef91f94362b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69c098842fd444e3b16ddcc0d00a7593":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ba70ade83ad4e9eb7071854136ff58f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d74783bee424a05a16a3e916a9f58fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_456d7bc8a58f4c29a6749a596106d3b8","max":1007,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f380177e174c494b8adf267b5d2db425","value":1007}},"6ff2cbfc671a44199990f79f9ff183da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3664081495e643a98434b4d4f9463a95","IPY_MODEL_e7d3d6e1bb8c4e11a6539132faa89996","IPY_MODEL_629bebe27de94f52ba9f32e8be9f6f97"],"layout":"IPY_MODEL_886bf2dac0e24035a6846aae82ae6073"}},"7076edac42574cfa91886c1526164ff8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_477aa4822a364c398b17b9eb7c0a1b21","IPY_MODEL_664eb6dd34ba4c0dac272a8ac79b6b03","IPY_MODEL_5b54b9c501cc4770abb8fa3faa7f94e6"],"layout":"IPY_MODEL_b382db97d90c4ed9bb6116e2d70176bb"}},"70a7853a03cb4a059f6e327ea8ea7095":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a79d086b10d94cfeb3d0780cca12ae09","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69c098842fd444e3b16ddcc0d00a7593","value":3}},"72824090c5be4b0fac5ace11f63198f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7312066626474b99a0843cb45b622466","IPY_MODEL_a483e018792141939a64e1d752fe54dc","IPY_MODEL_642e62327f09481cbb3eaee393bf4c47"],"layout":"IPY_MODEL_7de9a39719264c2e9114ad48fd347c66"}},"72ab2c1d08de4c62b6aeccba61c7fb5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7312066626474b99a0843cb45b622466":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68175a3852084de79743ef91f94362b8","placeholder":"​","style":"IPY_MODEL_bfb299f58a80424fba139f6ba9a3ba7a","value":"Downloading: 100%"}},"770946fdcb274169ae09d34dac3797fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de9a39719264c2e9114ad48fd347c66":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f2f20a9949140f982d61f0eaf9a7567":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"801a17ebd59844a89b55abc02457362b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49c801131a0d4924a4326dd1cca41e69","placeholder":"​","style":"IPY_MODEL_3dcfd30e46f6419484a51957294af60d","value":"Downloading: 100%"}},"846e00d05c444a029119698673fedac6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"860d2eeae7484934a0269b12a578500a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"886bf2dac0e24035a6846aae82ae6073":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b3f7562be7745f89b4a79759a24aef8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_416bae8a67d34d5aadff383c8462ef6f","placeholder":"​","style":"IPY_MODEL_f5abd1e9a96940efa82e3ba92fa44fc8","value":" 446k/446k [00:00&lt;00:00, 604kB/s]"}},"8c41bd61f17e4a55a19383bd416ac16f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25a6f2b76c5b46158c39c580d72d93b0","placeholder":"​","style":"IPY_MODEL_e220af41a2a6467db7871297e4add480","value":" 560/560 [00:00&lt;00:00, 5.94kB/s]"}},"8e48d2775c584922a4bd76ef4da6960c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49afecb48bc24563aecbcb4b4759ddf5","IPY_MODEL_dd9062a77020431a988990c57215fde1","IPY_MODEL_ef1c7f90c9164f4592ecb004478b32c6"],"layout":"IPY_MODEL_f5d1b023c9ff404c931d8f21aef67d2a"}},"8ed21e6b7e6444b7bdd69e5b0acce668":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_549ac1612d5e43c49f27ed14537bce9f","placeholder":"​","style":"IPY_MODEL_4b5561a417614ff386197a5c60206dfa","value":"Downloading: 100%"}},"8edb074b313b48c0ab6e7b33229b7b14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eece1a2d06a4109a946d23f0d3284f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cb6008b3d934ab9859c9ff65855c3ec","placeholder":"​","style":"IPY_MODEL_200c4fbc97c14485a87d97344c98f8c2","value":" 502M/502M [00:08&lt;00:00, 59.0MB/s]"}},"904f90485644422096befb8edbe53cfb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"911dd7b8186d49a09e568c60d33ddabe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93360276fb57431bbbce2f632d52f0d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d92b39134ad640e2b1f6461cb15dfc6e","placeholder":"​","style":"IPY_MODEL_c3acd2232c4e433f88af4bc8b634da6d","value":""}},"93e95d24eec54c20920f2020b2629125":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94b06c7011a245dcb8d75bba0d1817bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2f03c5e3c8a428981b5f006e417cc53","placeholder":"​","style":"IPY_MODEL_fde35d35de9a4b2cb539135e7a549c91","value":" 0/0 [00:00&lt;?, ? examples/s]"}},"9ac3331b9fc14071b9829b1387f8be26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd2142f7ddf746ecb12ea566f285af7c","IPY_MODEL_70a7853a03cb4a059f6e327ea8ea7095","IPY_MODEL_474e63ea64c44f6bbda84667d6a74036"],"layout":"IPY_MODEL_c086d97960684d56b0d30ec88fc49419"}},"a14d932614db4cc9a320f6a2c1e89fb9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a25d22e0a61d4c8eb6f37edc2cdb2175":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a29a397fd63d475a8fa26e97d0c78150":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0884e03afa97438e9332d1c9c7dd3d8f","placeholder":"​","style":"IPY_MODEL_463563e2389a4e4cab6344b7a0bf73e0","value":""}},"a483e018792141939a64e1d752fe54dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4e121094a7b431ab4993fe35f39397a","max":32751,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b12931c87df44deda723107286375f05","value":32751}},"a4e121094a7b431ab4993fe35f39397a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a55c6c45441346209b2d827538cf7eef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a605195ba0d542c7b0a6cbc690975a8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a79d086b10d94cfeb3d0780cca12ae09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a84adfc40c5747f69ac754134c9531c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8d458347d26491ca1edbcf7c2fe8910":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_860d2eeae7484934a0269b12a578500a","max":560,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93e95d24eec54c20920f2020b2629125","value":560}},"a9b9e81a3570409ba48d907f878950cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b12931c87df44deda723107286375f05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2055aff75ab40fc866376c779c45946":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b382db97d90c4ed9bb6116e2d70176bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4d52aa0f5f341b5a28a6b84a690183f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6ec91c0c92b4c0faaed75d0fb393e92":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7d5586a137b4a318fc0e7160ae13613":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba22aebfdb544aad83130732effa26d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb42e8f159f64ef3bc16556b42f96ff5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bca3917920f0484bbc1ee4f6a7b5954f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfb299f58a80424fba139f6ba9a3ba7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c086d97960684d56b0d30ec88fc49419":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3acd2232c4e433f88af4bc8b634da6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c41f180dfb7249aa9cbea14ab376917c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c68d74423795482cae935c614b3d8aad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fad219c4d6e46f5a504664ce4246e4b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe58ea91b19f45689534fc88433dfcf3","value":1}},"c73894249dc64e239c5d7e923717f31c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c85e7735da3740b39c3ec5aa97a170b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_01115ca094aa4e219c152c479fa1f13b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e625473a56d7423e901e6e8d8d11a5b4","value":1}},"caebeae14d25422f9f2a83e88981ebe0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb1b818f3c254961a2a166c0c2d8b5c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0470b6ed0c14f5382ad59a3c9a4ce45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ba70ade83ad4e9eb7071854136ff58f","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a55c6c45441346209b2d827538cf7eef","value":456318}},"d3877a6f8d9540d796e7627fb7c5ded4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f2f20a9949140f982d61f0eaf9a7567","max":898669,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c73894249dc64e239c5d7e923717f31c","value":898669}},"d3c22cbc812947f38bcf9be8fe1d4763":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d792e8b5289b402f87869a2f655517e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ff3923570b04a23946564e7a04a4eeb","IPY_MODEL_c68d74423795482cae935c614b3d8aad","IPY_MODEL_94b06c7011a245dcb8d75bba0d1817bc"],"layout":"IPY_MODEL_4d626c20ef854689be9260686a96f967"}},"d7e76ec5a5bc4c55ace3c541c61c634a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d83ecafccc6e4656af255f009c4be49f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d92b39134ad640e2b1f6461cb15dfc6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da974f946de745c08061294b590c38b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1d9e5d399e34f06b5b7a2679f0badad","placeholder":"​","style":"IPY_MODEL_a25d22e0a61d4c8eb6f37edc2cdb2175","value":" 878k/878k [00:00&lt;00:00, 1.69MB/s]"}},"dd2142f7ddf746ecb12ea566f285af7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a605195ba0d542c7b0a6cbc690975a8e","placeholder":"​","style":"IPY_MODEL_22d02623765940b48a06fd7f5fe51cff","value":"100%"}},"dd9062a77020431a988990c57215fde1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_846e00d05c444a029119698673fedac6","max":8232,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ecb25da55ac4caa8738e0f237106e6a","value":8232}},"e1d9e5d399e34f06b5b7a2679f0badad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e220af41a2a6467db7871297e4add480":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2f03c5e3c8a428981b5f006e417cc53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e625473a56d7423e901e6e8d8d11a5b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e745fcb8cbc047f3b30f4f8ea23fd869":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7d3d6e1bb8c4e11a6539132faa89996":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17675d5a53d64952a4644e0133a65537","max":357,"min":0,"orientation":"horizontal","style":"IPY_MODEL_310c472a313d47779ce5dcd836a92f94","value":357}},"e868898a8b624945bdf328c1a691d492":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ece9a2ccf8594878becb4fa531fb400c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed79044a702a40aea20564aa55616649":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a84adfc40c5747f69ac754134c9531c9","placeholder":"​","style":"IPY_MODEL_5aafc015755a4a04b4fd3a18312d0953","value":" 0.98k/0.98k [00:00&lt;00:00, 37.5kB/s]"}},"ef1c7f90c9164f4592ecb004478b32c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7fc3bd22ca942cca00bae7b38310a9b","placeholder":"​","style":"IPY_MODEL_e868898a8b624945bdf328c1a691d492","value":" 38.2k/? [00:00&lt;00:00, 1.38MB/s]"}},"f30860e5b4e741239a027b1b6f94ed10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f380177e174c494b8adf267b5d2db425":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4def5ba293943d695f1c53a3e966398":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5abd1e9a96940efa82e3ba92fa44fc8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5d1b023c9ff404c931d8f21aef67d2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7fc3bd22ca942cca00bae7b38310a9b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbcc518d08ee431086dcb9ff888c2b9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbdaeb25b94a445c932cc4a1e868387c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bca3917920f0484bbc1ee4f6a7b5954f","placeholder":"​","style":"IPY_MODEL_b4d52aa0f5f341b5a28a6b84a690183f","value":"Downloading: 100%"}},"fde35d35de9a4b2cb539135e7a549c91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe58ea91b19f45689534fc88433dfcf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}